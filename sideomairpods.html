<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Document</title>
    <link rel="stylesheet" href="GenerellCSS/GenerellCSS.css">
    <link rel="stylesheet" href="sideomairpods.css">
    <link rel="stylesheet" href="headerogfooter/footer.css">
    <link rel="stylesheet" href="headerogfooter/header.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.0/css/all.min.css">
</head>

<body>

    <header>
        <div class="bildelogo">
            <img src="bilder/logo.png" alt="">
        </div>

        <nav>
           <a href="index.html" class="fontawsome">
                <i class="fa-solid fa-house"></i>
                <p>Tilbake til hovedside</p>

            </a>
            <a href="Sider/omoss.html">Om oss</a>
            <a href="Sider/infodigitaltutstyr.html">Digitalt utstyr</a>
        </nav>

    </header>

    <main>
        <section class="topp">

            <h1> Apple lanserer live oversettelse med Airpods </h1>
            <h2> Nå kan man overvinne språkbarrierer mens du reiser eller navigerer i fremmed land. </h2>

            <div class="introbilde">
                <div> <img src="bilder/airpods1.jpg">
                    <figcaption> Ny Airpodsfunksjon: "Live-oversetting" </figcaption>
                </div>
                <div class="journalistbox">
                    <div class="journalister">
                        Jenny Nakstad
                        <div class="journalist"> Journalist </div>
                    </div>
                </div>
        </section>

        <section class="infotekst">
            <p> Apple lanserte i september 2025 "Live Translation" for Airpods. Nå kan Airpods oversette samtaler med en
                funksjon kalt Liveoversetting. Med Airpods kan du få en sanntidsoversettelse av tale mens du snakker
                med noen som bruker et annet språk.
            <p>Live-oversetting krever iOS 26 og støttes av AirPods Pro 3, Pro 2 og
                AirPods 4 med aktiv støydemping, mens funksjonen ble lansert senere i EU gjennom iOS 26.2 på grunn av
                regulatoriske krav.
            </p>
            <p class="tjukk"> Airpods sin live-oversetting funker slik: </p>
            <ul>
                <li>Du har AirPods i ørene.</li>
                <li>En annen person snakker til deg på et annet språk.</li>
                <li>iPhonen tolker språket og oversetter det med én gang.</li>
                <li>Du hører oversettelsen direkte i AirPods.</li>
                <li>Du kan selv svare, og stemmen din oversettes tilbake til den andre personen.</li>
            </ul>

            </p>
            <img src="bilder/airpods2.jpg">
            <p> For å bruke funksjonen, sett AirPods i ørene, åpne Oversett-appen på iPhonen,
                trykk på "Direkte", velg språkene og trykk "Start oversetting". Du kan også starte en samtale ved å
                holde på stilken på begge AirPods samtidig eller be Siri om å starte oversetting.
            </p>

            <h1 class="margin"> Teknologien bak panseret: </h1>
            <div class="carousel">
                <button class="arrow left">◀</button>

                <div class="track">
                    <figure class="slide">
                        <h2> Signalinnhenting fra AirPods </h2>
                        <p> AirPods Pro/Max bruker: </p>
                        <ul>
                            <li>Beamforming-mikrofoner for å isolere stemmen din</li>
                            <li>Støykansellering for å forbedre signal-til-støy-forholdet</li>
                            <li>On-device DSP i H1/H2-chipen for å gi iPhone et renset talefragment</li>
                        </ul>
                        <p> Dette betyr at stemmen din blir “pre-prosessert” før den sendes til iPhone, noe som gjør
                            talegjenkjenningen mer nøyaktig.</p>
                    </figure>

                    <figure class="slide">
                        <h2> Real-Time Speech Recognition </h2>
                        <p> Når lyden når iPhone, går den gjennom Apple sin on-device ASR-modell: </p>
                        <ul>
                            <li>Basert på nevrale nettverk </li>
                            <li>Benytter feature extraction </li>
                            <li>Kjører streaming-mode, der modellen gir løpende partielle resultater </li>
                        </ul>
                        Apple bruker en variant av en Conformer-modell (Convolution + Transformer), som er optimal
                        for mobil chip-arkitektur.</p>
                    </figure>

                    <figure class="slide">
                        <h2> Maskinoversettelse </h2>
                        <p>Når ASR gir en løpende transkripsjon, sendes tekstfragmentene til Apple sin Neural Machine
                            Translation-modell, som: </p>
                        <ul>
                            <li>er en Transformer-basert sekvens-til-sekvens-modell</li>
                            <li>kjører enten on-device for støttede språk eller med privat relay til Apple-servere hvis
                                språket krever større modeller </li>
                            <li>oversetter i del-setninger («segmenting») for å gi rask respons uten å vente på hele
                                setninger </li>
                        </ul>

                    </figure>

                    <figure class="slide">
                        <h2> Tekst-til-tale </h2>
                        <p>Når oversettelsen er klar, går den gjennom Apple sin TTS-motor: </p>
                        <ul>
                            <li>Nyere versjoner bruker en neural vocoder (WaveRNN/HiFi-GAN-lignende)</li>
                            <li>Genererer naturlig tale i sanntid</li>
                            <li>Kan strømme lydbitene direkte til AirPods før hele setningen er generert</li>
                        </ul>
                        <p>Det betyr at du hører taleoversettelsen nesten samtidig som den produseres.</p>
                    </figure>

                    <figure class="slide">
                        <h2> Two-Way Conversation Loop </h2>
                        <p>Hele pipeline er designet for full-dupleks flyt:</p>
                        <ol>
                            <li>Inngående tale fra den andre personen → iPhone-mikrofonen (eller AirPods hvis du bruker
                                Listen Mode)</li>
                            <li>ASR → NMT → TTS</li>
                            <li>Lyd sendes til AirPods og tekst vises i Translate-appen</li>
                        </ol>
                        Apple bruker parallell prosessering + buffering for å gjøre samtalen så “live” som mulig.
                        </p>
                    </figure>

                    <figure class="slide">
                        <h2> Latency-optimalisering </h2>
                        <p>For å redusere forsinkelser gjør Apple blant annet:</p>
                        <ul>
                            <li>Streaming inference i alle ledd (ASR, MT, TTS)</li>
                            <li>Hardware-akselerasjon via Neural Engine</li>
                            <li>End-to-end tilpasning mellom AirPods-chip og iPhone-chip</li>
                            <li>Lokal caching av språkhint og akustiske mønstre</li>
                            <li>Aggressiv komprimering av mellomrepresentasjoner</li>
                        </ul>
                        <p>Dette gir typisk total forsinkelse på ~200–500 ms.
                        </p>
                    </figure>


                </div>

                <button class="arrow right">▶</button>
            </div>
        </section>

<<<<<<< Updated upstream
         <section class="andresaker">
=======
        <section class="andresaker">
<<<<<<< Updated upstream
>>>>>>> Stashed changes
=======
>>>>>>> Stashed changes
            <a href="sideomVRbriller.html" class="saker"> <img class="sakerimg" src="bilder/forsideVR.png">
            <h2> Bruken av VR-briller under oprasjon </h2>
            <p> Flere sykehus ønsker å redusere bruken av sterke bedøvende medisiner. Teknologi hentet fra
                gaming-verdenen har blitt en løsning for å få dette til.</p>
            </a>
            <a href="sideomairpods.html" class="saker"><img class="sakerimg" src="bilder/airpods1.jpg">
                <h2> Apple lanserer live-oversetting med airpods </h2>
                <p> Ny airpodsfunksjon "live-oversetter". Apple lanserte i september 2025 "Live Translation" for
                    Airpods. Nå kan Airpods oversette samtaler med en funksjon kalt Liveoversetting.</p>
            </a>
            <a href="nvidiaartikkel.html" class="saker"><img class="sakerimg" src="bilder/nvidiasjef.jpg">
                <h2> Verdens viktigste selskap leverer tall </h2>
                <p> Er tek-oppgangen en boble? Mens Nvidia håver inn, svir kundene av penger. – Urovekkende, sier
                    investeringsdirektør Robert Næss.</p>
            </a>
        </section>



    </main>

    <footer class="footer">
        <div class="footercontainer">
            <div class="footer-section">
                <h3>NEONET</h3>
                <p>Nyheter om teknologi, AI, cybersikkerhet og digital utvikling.</p>
            </div>

            <div class="footer-section">
                <h4>Snarveier</h4>
                <a href="index.html">Forside</a>
                <a href="Sider/omoss.html">Om oss</a>
                <a href="Sider/infodigitaltutstyr.html">Digitalt utstyr</a>
            </div>

            <div class="footer-section">
                <h4>Kontakt</h4>
                <p>Email: redaksjon@neonet.no</p>
                <p>Telefon: +47 999 99 999</p>
            </div>
        </div>

        <div class="nederst">
            <p>© 2025 NEONET – Alle rettigheter forbeholdt.</p>
            <img src="bilder/logo.png" alt="">
        </div>
    </footer>
</body>

</html>